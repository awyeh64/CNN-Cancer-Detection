{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7ee8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# CNN libraries\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Dropout, MaxPooling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "# QOL libraries\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import random\n",
    "import os\n",
    "\n",
    "random.seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0db9e2",
   "metadata": {},
   "source": [
    "<h1>CNN Cancer Detection</h1>\n",
    "  \n",
    "  \n",
    "#### Table of Contents\n",
    "\n",
    "- [Problem and Data Description](#a)\n",
    "- [EDA](#b)\n",
    "- [DModel Architecture](#c)\n",
    "- [Results and Analysis](#d)\n",
    "    1. [Adding dropout layers](#da)\n",
    "    2. [Adding more hidden layers](#db)\n",
    "    3. [Increasing the filter size](#dc)\n",
    "    4. [Increasing the learning rate](#dd)\n",
    "    5. [Decreasing the learning rate](#de)\n",
    "    6. [Introducing batch normalization](#df)\n",
    "    7. [Changing the output activation function](#dg)\n",
    "    \n",
    "    \n",
    "    \n",
    "- [Conclusion](#e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27afe0",
   "metadata": {},
   "source": [
    "<h2>Problem and Data Description</h2><a name=\"a\"></a>\n",
    "\n",
    "This notebook is a submission for the Kaggle competition <a href = \"https://www.kaggle.com/c/histopathologic-cancer-detection/overview\">Histopathologic Cancer Detection</a>.  The premise of this competition is to create a convolutional neural network that will take a series of images taken from pathology scans, and output a prediction of whether or not the sample in question contains signs of metastatic cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ff331d",
   "metadata": {},
   "source": [
    "The data consists of two parts, and the first is a large folder of histopathologic scans of lymph nodes.  Each image has their respective image ID as their name, and is saved in a .tif format.  The images are also perfectly squared with dimensions of 96 pixels in width, 96 pixels in height, and has a depth of 3.  The folder is further split into a set of images for training our models, as well as another set for testing used to create the competition submission.\n",
    "\n",
    "The second part of the data is a labels dataset that lists the ids of each image in the training image set and their respective labels on whether or not there is evidence of cancer tissues in the center 32 x 32 pixel region of the iamge.  A label of 0 states that there is no sign of cancer in the respective scan, while a label of 1 states that there is signs of cancer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82deda29",
   "metadata": {},
   "source": [
    "In total, our training data has 220,025 images to use, and as we are not professional doctors, to the majority of us these images would make no sense and thus we will rely on the model to learn to predict our response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a81f2",
   "metadata": {},
   "source": [
    "<h2>Exploratory Data Analysis</h2><a name=\"b\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1ea6c3",
   "metadata": {},
   "source": [
    "As in this situation we are working with images as our source of data, our main dataframe will be built from the dataset of labels which we will use to keep track of the image IDs, their status, as well as their purpose for training and validation.\n",
    "\n",
    "For the purposes of this submission, we will be cutting down the number of images used to train from 220,025 to 13,000 in order to cut down on model training time to allow for more chances of testing a wider variety of hyper parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4282d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/histopathologic-cancer-detection/'\n",
    "df = pd.read_csv(path + 'train_labels.csv', dtype = str)\n",
    "df['file'] = df['id'] + '.tif'\n",
    "\n",
    "#\n",
    "df = df.sample(n = 13000, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_image(pic_id, train_test_validation = 'train'):\n",
    "    return path + train_test_validation + '/' + pic_id + '.tif'\n",
    "\n",
    "img = Image.open(match_image('f38a6374c348f90b587e046aac6079959adf3835'), 'r')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae33024",
   "metadata": {},
   "source": [
    "Here are example images of when there are no sign of metastatic cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b74bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize = (10, 6))\n",
    "\n",
    "for i, j in zip(axs.ravel(), df[df['label'] == '0'].sample(6, random_state = 17)['id']):\n",
    "    im = Image.open(match_image(j), 'r')\n",
    "    i.imshow(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd86da",
   "metadata": {},
   "source": [
    "Here are example images of when there are signs of metastatic cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed8b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 3, figsize = (10, 6))\n",
    "\n",
    "for i, j in zip(axs.ravel(), df[df['label'] == '1'].sample(6, random_state = 17)['id']):\n",
    "    img = Image.open(match_image(j), 'r')\n",
    "    i.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4886296",
   "metadata": {},
   "source": [
    "Now we check the distribution of our labeled classes, as well as some other standard checks such as ensuring that there are no Null or duplicate values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts(normalize = True).plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e87581c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6332c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cffc91d",
   "metadata": {},
   "source": [
    "From the barchart, we can see that there is a small imbalance between our class disparity which can be adjusted for later on.  Fortunately, the data does not come with any missing or duplicate values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbf5714",
   "metadata": {},
   "source": [
    "<h2>DModel Architecture</h2><a name=\"c\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7041fdf",
   "metadata": {},
   "source": [
    "To start, the 'train' data will be further split into a training dataset and a validation dataset, with a 8:2 split.   Furthermore, the model will be trained on the training set and scored on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e525923a",
   "metadata": {},
   "source": [
    "For our convolutional neural network we will be using a sequential model with the simple structure of convolution-convolution-MaxPool.  We will create a basic, barebones model with default hyperparameters as well as only one hidden layer.  This is to test how the model to interact with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73be44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size)) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(filter_1 * 2, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f74abfd",
   "metadata": {},
   "source": [
    "As I struggled with figuring out how to input images into my Sequential CNN model, I resorted to referencing the code in the notebook <a href= \"https://www.kaggle.com/code/fadhli/starter-code-keras-resnet50-0-9275-lb/notebook\">Starter Code Keras</a> to view how the ImageDataGenerator function was utilized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7220fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=lambda x:(x - x.mean()) / x.std() if x.std() > 0 else x)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe = train,\n",
    "    directory= path + 'train/',\n",
    "    x_col='file',\n",
    "    y_col='label',\n",
    "    has_ext=False,\n",
    "    batch_size=32,\n",
    "    seed=2018,\n",
    "    shuffle=True,\n",
    "    class_mode='binary',\n",
    "    target_size=(96,96),\n",
    "    validate_filenames = False\n",
    ")\n",
    "\n",
    "valid_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe = val,\n",
    "    directory= path + 'train/',\n",
    "    x_col='file',\n",
    "    y_col='label',\n",
    "    has_ext=False,\n",
    "    batch_size=32,\n",
    "    seed=2018,\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    target_size=(96,96),\n",
    "    validate_filenames = False\n",
    ")\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose=1, restore_best_weights=True)\n",
    "reducel = ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c83c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa19f55",
   "metadata": {},
   "source": [
    "From our accuracy diagram, we can tell that with our base model it can reach a relatively high training accuracy of over 0.84.  However, it is noticeably higher than than our validation accuracy which is a sign of a small bit of overfitting.  As this is just a base model, we can slowly start tweaking hyperparameters and the architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ce8c6",
   "metadata": {},
   "source": [
    "<h2>Results and Analysis</h2><a name=\"d\"></a>\n",
    "\n",
    "With the results from our base model, we will now undergo hyperparameter tuning in an attempt to improve our validation accuracy.  The ideas that we will test are:\n",
    "\n",
    "1. Adding dropout layers\n",
    "2. Adding more hidden layers\n",
    "3. Increasing the filter size\n",
    "4. Increasing the learning rate\n",
    "5. Decreasing the learning rate\n",
    "6. Introducing batch normalization\n",
    "7. Changing the output activation function\n",
    "\n",
    "Like the previous model, we will be mainly focusing on the accuracy statistic when the model is tested on the validation data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fe9a16",
   "metadata": {},
   "source": [
    "<h3>1.  Adding dropout layers.</h3><a name=\"da\"></a>\n",
    "\n",
    "The first step will be to add dropout layers after hidden layer and output layer.  This is to help with regularization purposes.  Thus we can see while the overall model performance does not change much, the difference between the training and validation scores have been minimalized by a significant amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e37c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_1.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_1.add(MaxPooling2D(pool_size)) \n",
    "model_1.add(Dropout(dropout_conv))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(filter_1 * 2, activation = 'relu'))\n",
    "model_1.add(Dropout(dropout_dense))\n",
    "model_1.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_1.compile(Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000da2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c1dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_1.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_1.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba489f",
   "metadata": {},
   "source": [
    "<h3>2. Adding more hidden layers</h3><a name=\"db\"></a>\n",
    "\n",
    "As our base model only has one hidden layer, we can significantly increase the training prowress by adding more hidden layers so that the model can better learn from the data.  We add two more layers, each with a filter size that is twice the size of the previous layer.  From the results, while the computation time increased, there is also an increase in both the training and validation accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab981fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "filter_3 = 128\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_2.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_2.add(MaxPooling2D(pool_size)) \n",
    "model_2.add(Dropout(dropout_conv))\n",
    "\n",
    "model_2.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_2.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_2.add(MaxPooling2D(pool_size)) \n",
    "model_2.add(Dropout(dropout_conv))\n",
    "\n",
    "model_2.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_2.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_2.add(MaxPooling2D(pool_size)) \n",
    "model_2.add(Dropout(dropout_conv))\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(256, activation = 'relu'))\n",
    "model_2.add(Dropout(dropout_dense))\n",
    "model_2.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_2.compile(Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53a09dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173eeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_2.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_2.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3231368a",
   "metadata": {},
   "source": [
    "<h3>3. Increasing the filter size</h3><a name=\"dc\"></a>\n",
    "\n",
    "Next we change the size of our filters from 3x3 to a 7x7 grid.  However, our results did not improve and thus this change will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce182c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "filter_3 = 128\n",
    "filter_size = ( 7, 7)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_3.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_3.add(MaxPooling2D(pool_size)) \n",
    "model_3.add(Dropout(dropout_conv))\n",
    "\n",
    "model_3.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_3.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_3.add(MaxPooling2D(pool_size)) \n",
    "model_3.add(Dropout(dropout_conv))\n",
    "\n",
    "model_3.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_3.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_3.add(MaxPooling2D(pool_size)) \n",
    "model_3.add(Dropout(dropout_conv))\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(256, activation = 'relu'))\n",
    "model_3.add(Dropout(dropout_dense))\n",
    "model_3.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_3.compile(Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9213d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3 = model_3.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9bcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_3.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_3.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24fda3d",
   "metadata": {},
   "source": [
    "<h3>4. Increasing the learning rate</h3><a name=\"dd\"></a>\n",
    "\n",
    "We attempted to test tweaking the learning rate by increasing it from 0.001 to 0.01.  However the results turned out to be disastrous with a very stable low score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a78880",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "filter_3 = 128\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_4.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_4.add(MaxPooling2D(pool_size)) \n",
    "model_4.add(Dropout(dropout_conv))\n",
    "\n",
    "model_4.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_4.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_4.add(MaxPooling2D(pool_size)) \n",
    "model_4.add(Dropout(dropout_conv))\n",
    "\n",
    "model_4.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_4.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_4.add(MaxPooling2D(pool_size)) \n",
    "model_4.add(Dropout(dropout_conv))\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(256, activation = 'relu'))\n",
    "model_4.add(Dropout(dropout_dense))\n",
    "model_4.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_4.compile(Adam(learning_rate = 0.01), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = model_4.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_4.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_4.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240417ea",
   "metadata": {},
   "source": [
    "<h3>5. Decreasing the learning rate</h3><a name=\"de\"></a>\n",
    "\n",
    "Instead of increasing the learning rate, we test what happens when the learning rate is decreased to 0.0001.  While not as bad as when the learning rate is increased, there are signs of severe overfitting.  Thus in the end, our default learning rate of 0.001 is a good rate to settle with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e791211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "filter_3 = 128\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_5.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_5.add(MaxPooling2D(pool_size)) \n",
    "model_5.add(Dropout(dropout_conv))\n",
    "\n",
    "model_5.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_5.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_5.add(MaxPooling2D(pool_size)) \n",
    "model_5.add(Dropout(dropout_conv))\n",
    "\n",
    "model_5.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_5.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_5.add(MaxPooling2D(pool_size)) \n",
    "model_5.add(Dropout(dropout_conv))\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(256, activation = 'relu'))\n",
    "model_5.add(Dropout(dropout_dense))\n",
    "model_5.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_5.compile(Adam(learning_rate = 0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1acce",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5 = model_5.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d49500",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_5.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_5.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2964d1ca",
   "metadata": {},
   "source": [
    "<h3>6. Introducing batch normalization</h3><a name=\"df\"></a>\n",
    "\n",
    "Similar to dropout layers, batch normalization is another regularization method we can employ.  From the results, both the training accuracy and the validation accuracy have increased slightly over the previous methods.  Thus this is a change we can keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99501625",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "filter_3 = 128\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_6 = Sequential()\n",
    "\n",
    "model_6.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling2D(pool_size)) \n",
    "model_6.add(Dropout(dropout_conv))\n",
    "\n",
    "model_6.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling2D(pool_size)) \n",
    "model_6.add(Dropout(dropout_conv))\n",
    "\n",
    "model_6.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(MaxPooling2D(pool_size)) \n",
    "model_6.add(Dropout(dropout_conv))\n",
    "\n",
    "model_6.add(Flatten())\n",
    "model_6.add(Dense(256, activation = 'relu'))\n",
    "model_6.add(BatchNormalization())\n",
    "model_6.add(Dropout(dropout_dense))\n",
    "model_6.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model_6.compile(Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3262788",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6 = model_6.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd7eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_6.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_6.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c4e74",
   "metadata": {},
   "source": [
    "<h3>7. Changing the output activation function</h3><a name=\"dg\"></a>\n",
    "\n",
    "For our final hyperparameter tuning, we will try changing the activation function of our output layer from a sigmoid activation to a softmax activation.  However as seen from our results, a model with a softmax activation function proved to be the worst out of all our current models.  This is most likely due to sigmoid being preferable for binary outputs while softmax is more geared for numerous categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6bbd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_1 = 32\n",
    "filter_2 = 64\n",
    "filter_3 = 128\n",
    "filter_size = ( 3, 3)\n",
    "img_width = img.width # 96\n",
    "img_height = img.height # 96\n",
    "img_depth = 3 # RGB\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.5\n",
    "pool_size = ( 2, 2)\n",
    "\n",
    "model_7 = Sequential()\n",
    "\n",
    "model_7.add(Conv2D(filter_1, filter_size, activation = 'relu', input_shape = (img_width, img_height, img_depth)))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Conv2D(filter_1, filter_size, activation = 'relu'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(MaxPooling2D(pool_size)) \n",
    "model_7.add(Dropout(dropout_conv))\n",
    "\n",
    "model_7.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Conv2D(filter_2, filter_size, activation = 'relu'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(MaxPooling2D(pool_size)) \n",
    "model_7.add(Dropout(dropout_conv))\n",
    "\n",
    "model_7.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Conv2D(filter_3, filter_size, activation = 'relu'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(MaxPooling2D(pool_size)) \n",
    "model_7.add(Dropout(dropout_conv))\n",
    "\n",
    "model_7.add(Flatten())\n",
    "model_7.add(Dense(256, activation = 'relu'))\n",
    "model_7.add(BatchNormalization())\n",
    "model_7.add(Dropout(dropout_dense))\n",
    "model_7.add(Dense(1, activation = 'softmax'))\n",
    "\n",
    "model_7.compile(Adam(learning_rate = 0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a093eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_7 = model_7.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5,\n",
    "                   callbacks=[reducel, earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343b274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_7.history['val_accuracy'], label = 'validation accuracy')\n",
    "plt.plot(history_7.history['accuracy'], label = 'training accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcfff3a",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2><a name=\"e\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57540a",
   "metadata": {},
   "source": [
    "In the end, the 6th model proved to have the best performance.  This was the model that had dropout layers, 3 hidden layers, 3x3 filter size, a learning rate of 0.001, batch normalization, and a sigmoid activation function.\n",
    "\n",
    "Some key takeaways from this was the importance of regularization methods, as without them to help combat overfitting there would be a large difference in performance between using the training data versus any other data.  Another thing of note is the learning rate, as a higher as well as lower learning rate lead to a significant decrease in performance.  However as this is a spectrum rather than discrete category, some more testing could be done to find if there is a more optimal value than 0.001.\n",
    "\n",
    "It is also of note that for the sake of ease of access, we only used 13,000 of the original 220,025 images to train our model with.  If more data was utilized, some hyperparameters could have either a more positive or negative effect on model performance, which is an improvement that could be tested in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e676b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "hst = [ history_1, history_2, history_3, history_4, history_5, history_6, history_7]\n",
    "hst_val = [ max(i.history['val_accuracy']) for i in hst ]\n",
    "\n",
    "plt.scatter(range(1,8), hst_val)\n",
    "plt.xlabel('model #')\n",
    "plt.ylabel('max')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72faa3e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_f = model_6\n",
    "history_f = history_6\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory= path + 'test1/',\n",
    "    batch_size=1,\n",
    "    seed=2018,\n",
    "    shuffle=False,\n",
    "    class_mode='binary',\n",
    "    target_size=(96,96)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069e4c59",
   "metadata": {},
   "source": [
    "With our final model chosen model, we can create our predictions on the proper test images and save them as our submission 'output.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3928df66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = model_f.predict(test_generator, steps = 57458, verbose = 1)\n",
    "\n",
    "ps = [i for j in p for i in j]\n",
    "preds = pd.DataFrame({'id': test_generator.filenames, 'label':ps})\n",
    "preds['id'] = preds['id'].str.slice(5, -4)\n",
    "\n",
    "preds.to_csv('output.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea14337",
   "metadata": {},
   "source": [
    "From our submission, the model ends up with a score of 0.8636 in the leaderboards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
